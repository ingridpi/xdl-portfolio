\chapter{Legal, Social, Ethical and Professional Issues} \label{ch:issues}

The development and deployment of \acrfull{drl} algorithms to perform profitable portfolio allocation raises several legal, social, ethical and professional issues that must be considered. The incorporation of post-hoc explainable techniques to understand, interpret and clarify the decision-making process of these algorithms is a crucial step towards addressing these concerns. This chapter explores them in detail, referencing relevant regulatory frameworks and professional codes of conducts, and highlights potential mitigation strategies.

\section{Legal Issues} \label{sec:legal-issues}

When deploying \acrfull{ml} algorithms in finance, the \acrfull{eu}'s \acrfull{aiact} \cite{AIAct2024} classifies them as high-risk under Article 6 due to their potential impact on an individual's economic well-being. Consequently, high-risk systems must comply with Chapter 3 - Section 2, Articles 9-15, which include the obligations for risk management, data governance, documentation, transparency and human supervision. In particular, Article 13 requires that high-risk AI systems's outputs are interpretable. The use of explainability techniques ensures that the decision-making process of the algorithm can be understood and justified, thus adhering to the legal requirements set forth by the \acrshort{aiact}.

In addition, \gls{algorithmictrading} systems must adhere to the \acrlong{eu} directive on \acrfull{mifid} \cite{MiFIDII} and the \acrfull{uk} \acrfull{fca} guidance on \textit{Algorithmic Trading Compliance in Wholesale Markets} \cite{FCA2018}. These regulations require robust governance and oversight frameworks, risk controls and thorough testing infrastructure. In this project, \gls{backtesting} has been carried out to assess the algorithm's performance under varying market conditions followed by explainability techniques to enable the auditability of the system.

\section{Social Issues} \label{sec:social-issues}

Despite the growing exposure to \acrfull{ai} systems with the rise of \acrfullpl{llm}, there is still a significant lack of understanding and trust in these systems. Some of the reasons behind this mistrust include the \gls{blackbox} nature of models, making outputs hard to interpret, lack of human-like qualities in the models, and perceived limitations to adapt to new situations and learn from previous mistakes.

In the context of this work, the integration of explainability techniques addresses the black box behaviour of the implemented technology by offering clear, data-driven justifications. However, transparency must also be accessible. It is essential to provide a user-friendly interface to easily access the explanations and generate plain language descriptions for non-technical audiences.

\section{Ethical Issues} \label{sec:ethical-issues}

The ethical implications of \acrshort{drl} in portfolio optimisation are multifaceted. The primary concern is the potential for these systems to make decisions that may not align with human values or ethical standards. For instance, if the algorithm prioritises profit maximisation without considering the social and/or environmental impacts of its investment choices, it could lead to unethical outcomes, such as supporting companies with poor labour practices or those contributing to environmental degradation. To address this concern, the following practices can be put in place:
\begin{enumerate}
    \item the end-user should have full control over the assets included in their portfolio, allowing them to exclude companies that do not meet their ethical values; and
    \item the environment's representation can be expanded to include ethical dimensions, like social impact or environmental sustainability metrics.
\end{enumerate}

Regarding the environment representation, it was not possible to incorporate such data as it is not readily available nor in a standardised format. This is why, although there was an interest to broaden the environment representation to include other sources outside of the financial domain, it was not feasible to do so in this thesis.

A critical point in portfolio allocation is risk management. In this research, a performance metric that balances return maximisation and risk minimisation is used for hyper-parameter tuning, ensuring that the agent learns to avoid overly risky investments. Additionally, the inclusion of a risk-free asset enables a safe-guard mechanism. The agent can be implemented to allocate all the resources to cash when market volatility exceeds a pre-defined threshold and resume only when said volatility decreases.

Finally, potential biases in the training data or model structure could result in allocations favouring certain industries or assets classes. This thesis mitigates such biases by constructing a portfolio from diversified indices (Appendix \ref{sec:datasets-equities}) and using explainability techniques to audit the decisions for systematic biases.

\section{Professional Issues} \label{sec:professional-issues}

In a research project of this calibre, it is crucial to conduct the work in accordance with the \acrfull{bcs} Code of Conduct \cite{BCSCodeConduct} and the \acrfull{iet} Rules of Conduct \cite{IETRules}. Particular focus must be put in ensuring that all non-original work and external contributions are explicitly acknowledged, following the principles of the \acrshort{bcs} Code of Conduct \cite{BCSCodeConduct}. This is not only limited to the written product, but the utmost consideration must be put in explicitly acknowledging all third-party libraries, datasets and code and following their use guidelines.
