\chapter{Legal, Social, Ethical and Professional Issues} \label{ch:issues}

The development and deployment of \acrfull{drl} algorithms to perform profitable portfolio allocation raises several legal, social, ethical and professional issues that must be considered. The incorporation of post-hoc explainable techniques to understand, interpret and clarify the decision-making process of these algorithms is a crucial step towards addressing these. This chapter will explore these concerns in detail, highlighting remediating circumstances and potential solutions.

\section{Legal Issues} \label{sec:legal-issues}

When it comes to the legal ramifications of deploying \acrfull{ml} algorithms in finance, under the \acrfull{eu}'s \acrfull{aiact} \cite{AIAct2024} their use can be classified as high-risk per Article 6 \footnote{https://artificialintelligenceact.eu/article/6/} due to their potential impact on an individuals' economic well-being. Consequently, such systems must comply with the requirements set in Section 2, Articles 9-15 \footnote{https://artificialintelligenceact.eu/section/3-2/}, which outline the obligations for high-risk AI systems, including risk assessment, data governance, and transparency measures. Particularly, to comply with Article 13 \footnote{https://artificialintelligenceact.eu/article/13/}, which outlines that high-risk AI systems must "enable deployers to interpret a system's output", the use of explainability techniques is essential. This ensures that the decision-making process of the algorithm can be understood and justified, thus adhering to the legal requirements set forth by the \acrshort{aiact}.

Additionally, \Gls{algorithmictrading} systems must comply with the \acrlong{eu} directive on \acrfull{mifid} \cite{MiFIDII} and the \acrfull{fca} guidance on \textit{Algorithmic Trading Compliance in Wholesale Markets}. These regulations outline that algorithmic decision-making processes must be subject to risk controls and a governance and oversight framework, as well as robust and consistent development and testing processes, amongst others. 

Consequently, the deployment of this particular implementation of portfolio optimisation using \acrfull{drl} must ensure that it follows adequate testing procedures and implements the necessary safeguards to mitigate potential risks. Moreover, by already providing post-hoc explainability techniques, it ensures that the decision-making process can be interpreted and justified. 

\section{Social Issues} \label{sec:social-issues}

Despite the recent popularity of \acrfull{ai} systems with the rise of \acrfull{llm}, there is still a significant lack of understanding and trust in these systems. Some of the reasons behind the psychological reasons why people would be hesitant to fully embrace \acrshort{ai} systems include:
\begin{itemize}
    \item Black box behaviour, making it difficult for people to understand their decisions.
    \item Lacking human-like qualities, with a preference in users to interact with the human counterparty.
    \item Perceived inability of the systems to adapt to new situations and learn from previous mistakes.
\end{itemize}

For our particular use case, the incorporation of explainability techniques addresses the black box behaviour of the implemented technology. However, there is a difference between generating the explanations and the end-user being able to access and understand them. To bridge this gap, it is essential to provide a user-friendly interface that allows users to easily access the explanations and provides human language descriptions of the explanations. 

% MAYBE: Another important aspect to consider with regards to social issues is the employment impact of automated systems.

\section{Ethical Issues} \label{sec:ethical-issues}

The ethical implications of using \acrshort{drl} algorithms for portfolio optimisation are multifaceted. The primary concern is the potential for these systems to make decisions that may not align with human values or ethical standards. For instance, if the algorithm prioritises profit maximisation without considering the social or environmental impact of its investment choices, it could lead to unethical outcomes, such as supporting companies with poor labour practices or those contributing to environmental degradation. The main way to address this concern is through asset selection. An end-user should have full control over the assets included in their portfolio, allowing them to exclude companies that do not meet their ethical standards. 

Furthermore, there are implicit ways to include ethical considerations in the decision-making process of the algorithm by expanding the environment representation to incorporate ethical dimensions, such as social impact and environmental sustainability metrics. However, coming across such data can be challenging, as it might not be publicly available nor follow a standardised manner. This is why, although the interest to broaden the environment representation to include other sources outside of the financial domain in this research, it was not feasible to do so given the available resources. 

A critical point in portfolio allocation is the risk associated with an investment. Regardless of whether the decisions come from a more traditional approach or from an \acrshort{ai} system, the risk is there. The approach taken in this research is to incorporate a risk-adjusted returns as the reward function of the \acrshort{rl} agent. This allows the algorithm to learn to balance the maximisation of returns with the minimisation of risk, ultimately leading to a more robust portfolio. Additionally, it is possible to incorporate cash, i.e. the risk-free asset, in the portfolio, which can be used to hedge against market volatility and provide a buffer during downturns. By incorporating the risk-free asset, it is possible to implement a safe-guard mechanism, where the agent is programmed to halt the allocation to all other assets, when the volatility surpasses a certain threshold and resume only when said volatility decreases.

Finally, when it comes to the data, it is important to be aware of potential biases in the training data or in the model design that could result in the systematic over-allocation of assets to certain sectors or classes. To mitigate this risk, this thesis used well-known indices, which are comprised of a diverse set of assets across sectors, as outlined in Appendix \ref{sec:datasets-equities}. Moreover, the use of post-hoc explainability techniques allows for the identification of such biases by understanding the decision-making process of the algorithm. 
