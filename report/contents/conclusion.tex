\chapter{Conclusion} \label{ch:conclusion}

This thesis has examined the application of \acrfull{drl} algorithms for optimal portfolio allocation in dynamic financial markets. The primary objective was to develop an explainable model-agnostic framework capable of enhancing the understanding of any \acrshort{drl} algorithm's predictions. Such a tool would provide insights into the decision-making process of these complex models and facilitate auditability.

Five state-of-the-art \acrshort{drl} algorithms, namely \acrfull{a2c}, \acrfull{ppo}, \acrfull{ddpg}, \acrfull{td3} and \acrfull{sac}, were implemented and evaluated on a portfolio management task. To assess the behaviour of these algorithms in different market conditions, a comprehensive experimental setup was designed, involving various datasets and environment representations. The datasets ranged from equities to commodities and currencies, each presenting unique challenges and opportunities for the \acrshort{drl} algorithms. 

The results demonstrated that \acrshort{drl} algorithms can effectively learn and adapt to dynamic market conditions, achieving competitive performance compared to traditional portfolio management strategies. However, the challenge remains in finding the optimal hyper-parameters, uniquely suited to each algorithm and dataset combination, in order to be able to fully exploit their potential.

Regarding explainability, the framework developed in this thesis successfully enhances the interpretability, transparency and auditability of these \gls{blackbox} models. The incorporation of feature importance through a surrogate model, \acrfull{lime} analysis and \acrfull{shap} values provides an exhaustive methodology for understanding both individual predictions and the overall decision-making process of the models. However, the results highlight the superiority of the \acrshort{shap} technique, which is capable of providing global explanations and feature importance without the need for an additional layer, in conjunction with local explanations. 

\section{Future Work} \label{sec:future-work}

There are several areas where future research could enhance this work. The main limitation of this thesis has been the lack of computational resources, which would have enabled optimal hyper-parameter tuning, exploration of more extensive feature space and evaluation of reward functions. 

Firstly, any future work should aim to fully explore the hyper-parameter space for each of the \acrshort{drl} algorithms, datasets and environment representations. In a similar vein, current research in price prediction has investigated the impact of a smaller feature representation by performing feature engineering techniques, such as feature selection and dimensionality reduction. Such measures might not only improve model performance and reduce over-fitting, but also reduce computational requirements.

Secondly, even in the case of optimal hyper-parameter configuration, comparing the performance of the models to those of traditional methods left room for improvement. Exploring alternative reward functions, such as Sharpe ratio, incorporating additional constraints, such as transaction costs, or explicitly handling periods of high volatility could lead to more robust and effective trading strategies. 

Thirdly, the exclusion of a risk-free asset from the portfolio led to reduced performance in comparison to the benchmarks. Future work could include a risk-free asset, which would result in a more diversified and potentially less risky portfolio. In terms of real-world scenarios, portfolios tend to be composed of different asset classes. Although this thesis explored the performance of the algorithms in different classes, forthcoming research could investigate the performance of these algorithms in multi-asset class portfolios.

Finally, the current framework would benefit from a more user-friendly interface that allows users to provide their dataset and prediction function easily and explore the model's explanations interactively. Another direction is to add intrinsic interpretability methods directly within the \acrshort{drl} algorithms, such as attention-based mechanisms \cite{Cortes2024}, reducing the need for post-hoc explanation techniques.