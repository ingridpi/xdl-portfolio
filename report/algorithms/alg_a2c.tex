\begin{algorithmic}
\State \textbf{Initialise:}
\State \quad Global shared policy parameters $\theta$ and value parameters $\theta_v$
\State \quad Number of parallel workers $N$
\State \quad Global step counter $T \gets 0$
\State \quad Hyper-parameters: discount $\gamma$, max steps per update $t_{\max}$, max total steps $T_{\max}$, learning rates $\alpha_\pi, \alpha_v$
\Repeat
    \State Reset gradients: $d\theta \gets 0$, $d\theta_v \gets 0$
    \State Initialise empty batch storage for all workers
    \For{worker $i = 1$ to $N$}
        \State $t_{\text{start}} \gets t$
        \State Get initial state $s_t^{(i)}$ from worker $i$
        \Repeat
            \State Select action $a_t^{(i)} \sim \pi_\theta(\cdot | s_t^{(i)})$
            \State Execute $a_t^{(i)}$, observe reward $r_t^{(i)}$ and next state $s_{t+1}^{(i)}$
            \State Store $(s_t^{(i)}, a_t^{(i)}, r_t^{(i)})$ in worker $i$'s trajectory
            \State $t \gets t + 1$
        \Until{terminal $s_t^{(i)}$ or $t - t_{\text{start}} == t_{\max}$}
        \State $R^{(i)} = 
            \begin{cases}
                0 & \text{if terminal } s_t^{(i)} \\
                V_{\theta_v}(s_t^{(i)}) & \text{otherwise}
            \end{cases}$
        \For{$j \in \{t-1, \ldots, t_{\text{start}}\}$}
            \State $R^{(i)} \gets r_j^{(i)} + \gamma R^{(i)}$
            \State Accumulate gradients w.r.t. $\theta$:
            \State \quad $d\theta \gets d\theta + \nabla_{\theta} \log \pi_\theta(a_j^{(i)} | s_j^{(i)}) (R^{(i)} - V_{\theta_v}(s_j^{(i)}))$
            \State Accumulate gradients w.r.t. $\theta_v$:
            \State \quad $d\theta_v \gets d\theta_v + \nabla_{\theta_v} (R^{(i)} - V_{\theta_v}(s_j^{(i)}))^2$
        \EndFor
    \EndFor
    \State \textit{// Synchronous update: wait for all workers to complete}
    \State Average gradients: $d\theta \gets \frac{1}{N} d\theta$, $d\theta_v \gets \frac{1}{N} d\theta_v$
    \State Update $\theta \gets \theta + \alpha_\pi d\theta$, $\theta_v \gets \theta_v - \alpha_v d\theta_v$
    \State $T \gets T + N \times t_{\max}$
\Until{$T > T_{\max}$}
\end{algorithmic}
