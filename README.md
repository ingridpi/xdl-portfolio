# Explainable Deep Learning for Portfolio Optimisation

## Metadata

- **University**: [King's College London](https://www.kcl.ac.uk)
- **Master's Programme**: [M.Sc. in Computational Finance](https://www.kcl.ac.uk/study/postgraduate-taught/courses/computational-finance-msc)
- **Student**: Ingrid PÃ©rez Aguilera
- **Supervisor**: [Riaz Ahmad](https://www.cqf.com/why-cqf/lecturers/our-faculty/dr-riaz-ahmad)

## Folder Structure

- `agents`: Module containing the implementation of the DRL agent.
- `config`: Configuration files.
- `data`: Data files generated by running the examples.
- `environments`: Module containing the implementation of the portfolio optimisation environment.
- `examples`: Jupyter notebooks demonstrating the use of the different modules.
- `figures`: Folder containing the figures generated by running the examples.
- `logs`: Folder containing the logs generated by running the examples, output of the TensorBoard for training the agents.
- `models`: Folder to store the trained models. 
- `optimisation`: Module contain the implementation of the optimisation using Weights and Biases.
- `pbenchmark`: Module containing the implementation of the benchmark strategies.
- `preprocessor`: Module containing the implementation of the data downloading and preprocessing.
- `report`: Latex files for the report.
- `results`: Folder containing the results of the experiments, particularly the evaluation metrics of the DRL agents compared to the benchmark strategies.
- `visualiser`: Module containing the implementation of the visualisation tools.

## Setup Instructions

Pre-requisites:
- Python 3.12
- Virtual environment (optional but recommended). If not installed, you can install it using:
  ```bash
  pip install virtualenv
  ```


1. Clone the repository:
   ```bash
   git clone https://github.com/ingridpi/xdl-portfolio.git
   cd xdl-portfolio
   ```
2. Create a virtual environment (optional but recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate
   ```
3. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

## Usage Instructions

The recommended usage of the repo is to run the Jupyter notebooks in the `examples` folder. These notebooks demonstrate how to use the different modules and functionalities provided by the repo. 

1. Adjust the configurations in the `config/config.py` file as needed. This file contains the start and end dates for the data, the tickers to be used, and whether to use technical and macroeconomic indicators.
1. Run the Jupyter notebooks in the `examples` folder. Each notebook is self-contained and demonstrates a specific functionality or use case of the repo. However, there is a dependence on the order of execution, so it is recommended to run them sequentially.
1. `findownloader.ipynb`: Demonstrates how to download the data for the tickers specified in the `config/config.py` file.
1. `finpreprocessor.ipynb`: Demonstrates how to preprocess the data downloaded in the previous step. This includes calculating technical indicators, macroeconomic indicators, and other features.
1. `portfolio_optimisation.ipynb`: Demonstrates how to use the portfolio optimisation environment and train agents to optimise a portfolio of stocks using reinforcement learning.
1. `backtesting.ipynb`: Demonstrates how to use the benchmark strategies and compare the performance of the trained agents against these benchmarks.
1. `hyperparameter_tuning.ipynb`: Using [Weights and Biases](https://wandb.ai/site/), perform hyper-parameter tuning by running a sweep, whose configuration is in `config.py` and `config_models.py`.
1. `explainability.ipynb`: Demonstrates how to use the explainability tools (feature importance, LIME and SHAP) to understand the decision-making process of a single model. 

Note that to run the notebooks, it is necessary to update the `REPO_ROOT` variable at the top of each notebook. Additionally, a [Weights and Biases](https://wandb.ai/site/) account is required to perform hyper-parameter tuning.
